{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining 7331 - Fall 2019\n",
    "## Lab 2 - Classification\n",
    "\n",
    "* **Allen Ansari**\n",
    "* **Chad Madding**\n",
    "* **Yongjun (Ian) Chu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Cardiovascular diseases (CVD) are the no. 1 cause of death in US each year. To reduce the death rate, the best approach is by early detection and screening. In this Lab we will implemented decision tree, Random Forest ,KNN and Support Vector Machine (SVM) to look at predicting the probability of a patient having CVD based on results from medical examinations, such as blood pressure values and glucose content.\n",
    "The second classifier is to predict Cholesterol level for each patient by having those medical exams.\n",
    "The following categories are used for the analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "\n",
    "We will be performing an analysis of the cardiovascular diseases dataset found on Kaggle (https://www.kaggle.com/sulianova/cardiovascular-disease-dataset). Our analysis will consist of exploring the statistical summaries of the features, visualizing the attributes, and making conclusions from the visualizations and analysis.\n",
    "\n",
    "Our task is to predict the presence or absence of cardiovascular disease (CVD) using the patient examination results. \n",
    "\n",
    "There are 3 types of input features:\n",
    "\n",
    "- *Objective*: factual information;\n",
    "- *Examination*: results of medical examination;\n",
    "- *Subjective*: information given by the patient.\n",
    "\n",
    "|Feature   |Variable Type   |Variable   |Value Type   |\n",
    "|:---------|:--------------|:---------------|:------------|\n",
    "| Age | Objective Feature | age | int (days) |\n",
    "| Height | Objective Feature | height | int (cm) |\n",
    "| Weight | Objective Feature | weight | float (kg) |\n",
    "| Gender | Objective Feature | gender | categorical code |\n",
    "| Systolic blood pressure | Examination Feature | ap_hi | int |\n",
    "| Diastolic blood pressure | Examination Feature | ap_lo | int |\n",
    "| Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n",
    "| Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n",
    "| Smoking | Subjective Feature | smoke | binary |\n",
    "| Alcohol intake | Subjective Feature | alco | binary |\n",
    "| Physical activity | Subjective Feature | active | binary |\n",
    "| Presence or absence of cardiovascular disease | Target Variable | cardio | binary |\n",
    "\n",
    "For any binary data type, \"0\" means \"No\" and \"1\" means \"Yes\". All of the dataset values were collected at the moment of medical examination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents<a id=\"top\"></a>\n",
    "\n",
    "* **[Data Preparation Part 1](#Data_Preparation_Part_1)**\n",
    "    *  Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "* **[Data Preparation Part 2](#Data_Preparation_Part_2)**\n",
    "    *  Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "* **[Modeling and Evaluation 1](#Modeling_and_Evaluation_1)**\n",
    "    *  Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "* **[Modeling and Evaluation 2](#Modeling_and_Evaluation_2)**\n",
    "    *  Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "* **[Task 1](#Task_1)**\n",
    "    * **[1.1 Modeling and Evaluation 3](#1.1_Modeling_and_Evaluation_3)**\n",
    "         *  Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!\n",
    "    * **[1.2 Modeling and Evaluation 4](#1.2_Modeling_and_Evaluation_4)**\n",
    "         *  Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "    * **[1.3 Modeling and Evaluation 5](#1.3_Modeling_and_Evaluation_5)**\n",
    "         *  Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "    * **[1.4 Modeling and Evaluation 6](#1.4_Modeling_and_Evaluation_6)**\n",
    "         *  Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "* **[Task 2](#Task_2)**    \n",
    "    * **[2.1 Modeling and Evaluation 3](#2.1_Modeling_and_Evaluation_3)**\n",
    "         *  Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!\n",
    "    * **[2.2 Modeling and Evaluation 4](#2.2_Modeling_and_Evaluation_4)**\n",
    "         *  Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "    * **[2.3 Modeling and Evaluation 5](#2.3_Modeling_and_Evaluation_5)**\n",
    "         *  Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "    * **[2.4 Modeling and Evaluation 6](#2.4_Modeling_and_Evaluation_6)**\n",
    "         *  Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "* **[Deployment](#Deployment)**\n",
    "    *  How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would you deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\n",
    "* **[Exceptional Work](#Exceptional_Work)**\n",
    "    *  You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### Data_Preparation_Part_1 <a id=\"Data_Preparation_Part_1\"></a>\n",
    "* we obtained a CVD dataset from Kaggle. It consists of 70,000 records of patient’s data in 12 features, such as age, gender, systolic blood pressure, diastolic blood pressure and CVD status(binary, 1 or 0). The purpose of this dataset was to determine which medical aspects had the most bearing on whether a patient would had CVD or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data all necessary libraries we will be using in our estimation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import re\n",
    "import sklearn\n",
    "import statistics\n",
    "import random\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectPercentile, RFE, SelectFromModel\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Binarizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, auc, roc_curve\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, TimeSeriesSplit, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor,AdaBoostClassifier,RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Bring in data set\n",
    "df = pd.read_csv('data/cardio_train.csv', sep= ';') #read in the csv file\n",
    "\n",
    "# Show the dimension and the first 5 rows of the dataset\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our data preparation includes following steps:\n",
    "* Remove the \"id\" attribute as it is not needed in this assignment\n",
    "* Inspect each feature for NA values. If more than 75% of the feature contains NA, we replace that field with 0. If less than 75% is NA, then the median value of the column is used to replace the NA\n",
    "* Check for any categorical variables and using proper methods (like one-hot) to convert them to numerical variables\n",
    "* Remove all duplicate entries in the dataset\n",
    "* Search each feature for any outliers and remove them from dataset. We will keep the entries between 97.5% quantile and 2.5% quantile for those features which have outliers or incorrect data \n",
    "* Add new variable call Body mass index (BMI) which is commonly used in medical field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'id' column \n",
    "if 'id' in df:\n",
    "    del df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            0\n",
       "gender         0\n",
       "height         0\n",
       "weight         0\n",
       "ap_hi          0\n",
       "ap_lo          0\n",
       "cholesterol    0\n",
       "gluc           0\n",
       "smoke          0\n",
       "alco           0\n",
       "active         0\n",
       "cardio         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total missing values for each feature\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see the data type of each column of the CVD dataset and see if there are any categorical variables in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing values or NAs in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# are there any NA values in the dataset\n",
    "if df.isnull().values.any():\n",
    "    print('There are NAs or missing values in the datasets.')\n",
    "else:\n",
    "    print('There are no missing values or NAs in the dataset.')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "gender\n",
      "height\n",
      "weight\n",
      "ap_hi\n",
      "ap_lo\n",
      "cholesterol\n",
      "gluc\n",
      "smoke\n",
      "alco\n",
      "active\n",
      "cardio\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "# Are there any non-numbers in each column?\n",
    "for column in df:\n",
    "    print(column)\n",
    "    cnt=0\n",
    "    for row in df[column]:\n",
    "        try:\n",
    "            float(row)\n",
    "        except ValueError:\n",
    "            print(\"there is a non-numeric value: \" + row)\n",
    "            pass\n",
    "        cnt+=1\n",
    "        \n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values in the dataset are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows except first occurrence based on all columns are :\n",
      "         age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
      "10562  20495       1     165    70.0    120     80            1     1      0   \n",
      "21784  16793       1     165    68.0    120     80            1     1      0   \n",
      "38505  18988       1     164    65.0    120     80            1     1      0   \n",
      "40365  14552       1     158    64.0    120     80            1     1      0   \n",
      "42450  18353       1     169    67.0    120     80            1     1      0   \n",
      "44653  16937       2     170    70.0    120     80            1     1      0   \n",
      "45125  21280       1     165    65.0    120     80            1     1      0   \n",
      "45748  22077       1     175    69.0    120     80            1     1      0   \n",
      "45810  21230       1     164    62.0    120     80            1     1      0   \n",
      "48917  21945       1     165    60.0    120     80            1     1      0   \n",
      "50432  17493       2     169    74.0    120     80            1     1      0   \n",
      "52552  21943       1     165    65.0    120     80            1     1      0   \n",
      "56643  17535       2     165    65.0    120     80            1     1      0   \n",
      "56906  20293       1     162    70.0    110     70            1     1      0   \n",
      "57946  18955       1     165    75.0    120     80            1     1      0   \n",
      "58730  19858       1     165    68.0    120     80            1     1      0   \n",
      "60453  20516       1     164    66.0    120     80            1     1      0   \n",
      "60474  16805       1     157    67.0    120     80            1     1      0   \n",
      "62318  18979       1     165    65.0    120     80            1     1      0   \n",
      "64169  16160       1     168    65.0    120     80            1     1      0   \n",
      "65079  18210       1     160    60.0    120     80            1     1      0   \n",
      "65622  21778       1     160    58.0    120     80            1     1      0   \n",
      "66190  19059       1     165    65.0    120     80            1     1      0   \n",
      "68281  21119       1     160    60.0    120     80            1     1      0   \n",
      "\n",
      "       alco  active  cardio  \n",
      "10562     0       1       0  \n",
      "21784     0       1       0  \n",
      "38505     0       1       0  \n",
      "40365     0       1       0  \n",
      "42450     0       1       0  \n",
      "44653     0       0       0  \n",
      "45125     0       1       0  \n",
      "45748     0       1       1  \n",
      "45810     0       1       0  \n",
      "48917     0       1       0  \n",
      "50432     0       1       1  \n",
      "52552     0       1       1  \n",
      "56643     0       1       0  \n",
      "56906     0       1       0  \n",
      "57946     0       1       1  \n",
      "58730     0       1       0  \n",
      "60453     0       0       0  \n",
      "60474     0       1       0  \n",
      "62318     0       0       0  \n",
      "64169     0       1       1  \n",
      "65079     0       1       0  \n",
      "65622     0       1       0  \n",
      "66190     0       1       1  \n",
      "68281     0       0       1  \n",
      "\n",
      "There are 24 duplicated entries in the dataset!\n"
     ]
    }
   ],
   "source": [
    "#Are there any duplicate entries in the dataset?\n",
    "duplicateRowsDF = df[df.duplicated(keep='first')]\n",
    "\n",
    "print(\"Duplicate Rows except first occurrence based on all columns are :\")\n",
    "print(duplicateRowsDF)\n",
    "\n",
    "print(f\"\\nThere are {len(duplicateRowsDF)} duplicated entries in the dataset!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For duplicated entries, we think they were just from mistakes by entering more than once. These 24 entries should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69976, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove duplicates in the dataframe\n",
    "df.drop_duplicates(keep = 'first', inplace = True) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>69976.000000</td>\n",
       "      <td>69976.000000</td>\n",
       "      <td>69976.000000</td>\n",
       "      <td>69976.000000</td>\n",
       "      <td>69976.000000</td>\n",
       "      <td>69976.000000</td>\n",
       "      <td>69976.000000</td>\n",
       "      <td>69976.000000</td>\n",
       "      <td>69976.000000</td>\n",
       "      <td>69976.000000</td>\n",
       "      <td>69976.000000</td>\n",
       "      <td>69976.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>19468.950126</td>\n",
       "      <td>1.349648</td>\n",
       "      <td>164.359152</td>\n",
       "      <td>74.208519</td>\n",
       "      <td>128.820453</td>\n",
       "      <td>96.636261</td>\n",
       "      <td>1.366997</td>\n",
       "      <td>1.226535</td>\n",
       "      <td>0.088159</td>\n",
       "      <td>0.053790</td>\n",
       "      <td>0.803718</td>\n",
       "      <td>0.499771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2467.374620</td>\n",
       "      <td>0.476862</td>\n",
       "      <td>8.211218</td>\n",
       "      <td>14.397211</td>\n",
       "      <td>154.037729</td>\n",
       "      <td>188.504581</td>\n",
       "      <td>0.680333</td>\n",
       "      <td>0.572353</td>\n",
       "      <td>0.283528</td>\n",
       "      <td>0.225604</td>\n",
       "      <td>0.397187</td>\n",
       "      <td>0.500004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>10798.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-150.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>17664.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>19703.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>21327.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>23713.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>16020.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        gender        height        weight         ap_hi  \\\n",
       "count  69976.000000  69976.000000  69976.000000  69976.000000  69976.000000   \n",
       "mean   19468.950126      1.349648    164.359152     74.208519    128.820453   \n",
       "std     2467.374620      0.476862      8.211218     14.397211    154.037729   \n",
       "min    10798.000000      1.000000     55.000000     10.000000   -150.000000   \n",
       "25%    17664.000000      1.000000    159.000000     65.000000    120.000000   \n",
       "50%    19703.000000      1.000000    165.000000     72.000000    120.000000   \n",
       "75%    21327.000000      2.000000    170.000000     82.000000    140.000000   \n",
       "max    23713.000000      2.000000    250.000000    200.000000  16020.000000   \n",
       "\n",
       "              ap_lo   cholesterol          gluc         smoke          alco  \\\n",
       "count  69976.000000  69976.000000  69976.000000  69976.000000  69976.000000   \n",
       "mean      96.636261      1.366997      1.226535      0.088159      0.053790   \n",
       "std      188.504581      0.680333      0.572353      0.283528      0.225604   \n",
       "min      -70.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "25%       80.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "50%       80.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "75%       90.000000      2.000000      1.000000      0.000000      0.000000   \n",
       "max    11000.000000      3.000000      3.000000      1.000000      1.000000   \n",
       "\n",
       "             active        cardio  \n",
       "count  69976.000000  69976.000000  \n",
       "mean       0.803718      0.499771  \n",
       "std        0.397187      0.500004  \n",
       "min        0.000000      0.000000  \n",
       "25%        1.000000      0.000000  \n",
       "50%        1.000000      0.000000  \n",
       "75%        1.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#are there any outliers in the dataset?\n",
    "\n",
    "#boxplot of all the variables\n",
    "plt.figure(figsize=(15, 15))\n",
    "ax = df.boxplot()\n",
    "ax.set_yscale('log')\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the simple statistical information and the boxplots above, we can easily see that there are some incorrect data points there. For example, the blood pressure has negative readings and the maximum readings for both Systolic blood pressure (ap_hi) and Diastolic blood pressure (ap_lo) are over 10,000, which are obviously mistakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66169, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to only keep the entries between 97.5% quantile and 2.5% quantile for ap_hi and ap_lo\n",
    "df.drop(df[(df['ap_hi'] > df['ap_hi'].quantile(0.975)) | (df['ap_hi'] < df['ap_hi'].quantile(0.025))].index,inplace=True)\n",
    "df.drop(df[(df['ap_lo'] > df['ap_lo'].quantile(0.975)) | (df['ap_lo'] < df['ap_lo'].quantile(0.025))].index,inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also notice that there are some abnormal values in column \"weight\" and \"height\". The minimum weight is 10 kg and maximum 200 kg. and the minimum height is 55 cm and maximum is 250 cm. Obviously these values are outliers as they don't represent the values for normal people. So, we decided to remove these by only keeping the values from 2.5 to 97.5 percentile range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[(df['weight'] > df['weight'].quantile(0.975)) | (df['weight'] < df['weight'].quantile(0.025))].index,inplace=True)\n",
    "df.drop(df[(df['height'] > df['height'].quantile(0.975)) | (df['height'] < df['height'].quantile(0.025))].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above statistics table we realized that age measured in days, for better description we decided to convert age variable to be in years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['years'] = (df['age'] / 365).round().astype('int')\n",
    "if 'age' in df:\n",
    "    del df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  \\\n",
       "0       2     168    62.0    110     80            1     1      0     0   \n",
       "1       1     156    85.0    140     90            3     1      0     0   \n",
       "2       1     165    64.0    130     70            3     1      0     0   \n",
       "3       2     169    82.0    150    100            1     1      0     0   \n",
       "4       1     156    56.0    100     60            1     1      0     0   \n",
       "\n",
       "   active  cardio  years  \n",
       "0       1       0     50  \n",
       "1       1       1     55  \n",
       "2       0       1     52  \n",
       "3       1       1     48  \n",
       "4       0       0     48  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Body mass index (BMI) is commonly used in medical field. It is a key index for relating weight to height. BMI is a person's weight in kilograms (kg) divided by his or her height in meters squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define BMI\n",
    "df['BMI'] = df['weight']/((df['height']/100)**2)\n",
    "# converting BMI range to categorical as 1 = underweight,2 = normal, 3 = overweight and 4 = obese\n",
    "df['BMI'] = df['BMI'].apply(lambda x: 1 if x<18.5 else(2 if x>=18.5 and x<25 else( 3 if x >= 25 and x < 30 else 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in CDV dataset gender shown as 1 for female and 2 for men. Since this is a binary feature showing these 2 categories as 1 and 2 does not make sense, so we are change the gender levels to be 0 for female and 1 for male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change gender levels: 1 to 0 (female) and 2 to 1 (male)\n",
    "df['gender'] = df['gender'].apply(lambda x:0 if x == 1 else(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### Data Preparation Part 2<a id=\"Data_Preparation_Part_2\"></a>\n",
    "* Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final dataset includes 13 features and 60728 entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60728 entries, 0 to 69999\n",
      "Data columns (total 13 columns):\n",
      "gender         60728 non-null int64\n",
      "height         60728 non-null int64\n",
      "weight         60728 non-null float64\n",
      "ap_hi          60728 non-null int64\n",
      "ap_lo          60728 non-null int64\n",
      "cholesterol    60728 non-null int64\n",
      "gluc           60728 non-null int64\n",
      "smoke          60728 non-null int64\n",
      "alco           60728 non-null int64\n",
      "active         60728 non-null int64\n",
      "cardio         60728 non-null int64\n",
      "years          60728 non-null int32\n",
      "BMI            60728 non-null int64\n",
      "dtypes: float64(1), int32(1), int64(11)\n",
      "memory usage: 6.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature   |Variable Type   |Variable   |Value Type   |\n",
    "|:---------|:--------------|:---------------|:------------|\n",
    "| Years | Objective Feature | years | int (years) |\n",
    "| Height | Objective Feature | height | int (cm) |\n",
    "| Weight | Objective Feature | weight | float (kg) |\n",
    "| Gender | Objective Feature | gender | categorical code |\n",
    "| Systolic blood pressure | Examination Feature | ap_hi | int |\n",
    "| Diastolic blood pressure | Examination Feature | ap_lo | int |\n",
    "| Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n",
    "| Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n",
    "| Smoking | Subjective Feature | smoke | binary |\n",
    "| Alcohol intake | Subjective Feature | alco | binary |\n",
    "| Physical activity | Subjective Feature | active | binary |\n",
    "| Body Mass Index | Examination Feature | bmi | int |\n",
    "| Presence or absence of cardiovascular disease | Target Variable | cardio | binary |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### Modeling and Evaluation 1<a id=\"Modeling_and_Evaluation_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this LAB was to determine which medical aspects had the most bearing on whether a patient would had CVD or not and also to classified cholesterol level each patient into normal and high cholesterol level.\n",
    "\n",
    "A receiver operating characteristic curve, ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied which is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n",
    "A ROC curve can be used to select a threshold for a classifier which maximizes the true positives, while minimizing the false positives.\n",
    "\n",
    "The AUC represents a model’s ability to discriminate between positive and negative classes. An area of 1.0 represents a model that made all predictions perfectly. An area of 0.5 represents a model as good as random. Most classifiers have AUCs that fall somewhere between these two values. Therefore, the overall model performances can be compared by considering the AUC.\n",
    "\n",
    "In addition to ROC-AUC metric, we use the other classification metrics in our models too. \n",
    "\n",
    "1- Accuracy: Is the proportion of the total number of predictions that were correct over all kinds predictions made. Accuracy is a good measure when the target variable classes in the data are nearly balanced.\n",
    "\n",
    "Accuracy = (TP + TN)/(TP + FP + FN + TN)\n",
    "\n",
    "2- Precision: Which is also called Positive Predictive Value and is the proportion of positive cases that were correctly identified.\n",
    "\n",
    "Precision = (TP) / (TP + FP)\n",
    "\n",
    "3- Recall or Sensitivity: Is the proportion of actual positive cases which are correctly identified.\n",
    "\n",
    "Recall = (TP) / (TP + FN)\n",
    "\n",
    "Recall gives us information about a model performance with respect to false negatives (how many did we miss), while precision gives us information about its performance with respect to false positives (how many did we caught).\n",
    "\n",
    "So basically, if we want to focus more on minimizing False Negatives, we would want our Recall to be as close to 100% as possible without precision being too bad and if we want to minimize False positives, then our focus should be to make Precision as close to 100% as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### Modeling and Evaluation 2<a id=\"Modeling_and_Evaluation_2\"></a>\n",
    "* Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50.801937\n",
       "1    49.198063\n",
       "Name: cardio, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cardio percentage split\n",
    "(df['cardio'].value_counts()/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    75.754183\n",
       "2    13.091161\n",
       "3    11.154657\n",
       "Name: cholesterol, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cholesterol percentage split\n",
    "(df['cholesterol'].value_counts()/len(df))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, CVD dataset will be split into training and test sets as 80/20. For data training, a standard 10-fold cross validation technique are used, in this technique dataset will split into 10 equal sections, train on nine of the sections and score against the last section. This method will cycle through 10 times so that the each of the 10 sections is used as a holdout sample. We chose to shuffle the data during the cross validation to provide a higher confidence there was no grouping of schools that we did not notice.\n",
    "\n",
    "There is another option available called the Stratified k-fold technique which works to balance the ratio of labels used in each fold. Our dependent variable (cardio) has approximately a 49-51% split (see above), and with a large enough data set we can have a high level of confidence of a random split in the data without using Stratified techniques. In other hand for Cholesterol there is imbalanced distribution between classes (see above). The major class is patients with normal cholesterol level(75.7%) followed by above normal (13%) and well above normal (11%). Since the important thing is that to know if patient has cholesterol or not we decided to combine both above normal classes (2 and 3) and use Modified synthetic minority oversampling technique (MSMOTE) technique which takes a subset of data from the minority class as an example and then new synthetic similar instances are created. These synthetic instances are then added to the original dataset. The new dataset is used as a sample to train the classification models.\n",
    "\n",
    "We chose a K fold (10 folds) validation algorithm, however a Shuffle Split may have performed just as well with this size data set. Where Shuffle Split is capable of creating n folds and fitting the data using n-1 to train and 1 to test against, there is a chance the same data will appear in the test set each time the data is sampled. We chose K fold to insure each value is used in the training set.\n",
    "\n",
    "With the 10-fold cross validation we will be using a grid search technique, which will test a number of different parameters to determine the best final model. Different classification algorithms will have different parameters that can be set, so these will be tested with the grid search method.\n",
    "\n",
    "Since CVD dataset does not have so many features and it has only 60000 entries dimensionality reduction techniques are not used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our basic pipeline includes observation scaling and model classification steps. Observation scaling is a common step for all models. For this step the 'standardscaler' is used, which will scale our variables. This improves our prediction outcomes and makes later feature interpretation significantly easier, since all coefficients will be on the same scale.\n",
    "\n",
    "The same random seed of 101 is used for all models that take a random state seed to eliminate the variability of getting different results between running our models so that we are able to hold which model is going to be the best model, for later interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "# Task 1<a id=\"Task_1\"></a>\n",
    "\n",
    "### 1.1 Modeling and Evaluation 3<a id=\"1.1_Modeling_and_Evaluation_3\"></a>\n",
    "* Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cardio prediction we tried 4 different algorithms to create a model which has superior prediction capabilities based on the ROC/AUC scoring parameter:\n",
    "\n",
    "* Support Vector Machine (SVM)\n",
    "* K-Nearest Neighbor\n",
    "* Random Forest Classification\n",
    "* Decision Tree Classifier\n",
    "\n",
    "A ROC/AUC plot will be created for each model and summarized our findings based on the combined results for these different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the pipeline template where we will test for scaling, and classification.\n",
    "k_fold = KFold(n_splits=10,shuffle=True)\n",
    "pipe = Pipeline([ ('scale', StandardScaler()), \n",
    "                  ('clf', GradientBoostingClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a cross validation using the best parameters for the model which it is passed we use below code that borrowed form  Dr. Jake Drew's 2017HighlySegregatedHighSchoolCampuses Jupyter Notebook provided to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateClassifierEstimator(classifierEstimator, X, Y, cv):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, X, Y, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Rreavg = scores['test_recall'].mean()\n",
    "    \n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average Recall for all cv folds is: \\t\\t\\t {Rreavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Rreavg=Rreavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "    print(scoresResults)\n",
    "    return scoresResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60728, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separating input data into two parts X (features) and Y (target)\n",
    "features = [\"gender\", \"height\", \"weight\", \"ap_hi\", \"ap_lo\", \"cholesterol\", \"gluc\", \"smoke\", \"alco\", \"active\", \"years\", \"BMI\"]\n",
    "\n",
    "X = df[features].copy()\n",
    "\n",
    "Y= df[['cardio']].copy()\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1 : Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scale',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('clf',\n",
       "                                        GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                                   init=None,\n",
       "                                                                   learning_rate=0.1,\n",
       "                                                                   loss='deviance',\n",
       "                                                                   max_depth=3,\n",
       "                                                                   max_features=None,\n",
       "                                                                   max_leaf_nodes=N...\n",
       "                                               random_state=101, shuffle=True,\n",
       "                                               tol=0.001,\n",
       "                                               validation_fraction=0.1,\n",
       "                                               verbose=0, warm_start=False)],\n",
       "                         'clf__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'clf__class_weight': ['balanced', None],\n",
       "                         'clf__loss': ['hinge'], 'clf__max_iter': [1000, 1500],\n",
       "                         'clf__penalty': ['l2'], 'clf__random_state': [101]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM_SGD 10-fold cross-validation \n",
    "\n",
    "param_grid = { 'clf': [SGDClassifier()]\n",
    "              ,'clf__loss': ['hinge']\n",
    "              ,'clf__penalty':['l2']\n",
    "              ,'clf__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "              ,'clf__class_weight': ['balanced', None]\n",
    "              ,'clf__random_state': [101]\n",
    "              ,'clf__max_iter':[1000,1500]\n",
    "              \n",
    "             }\n",
    "\n",
    "#Create a grid search object using the above parameters \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "SVMGridSearch = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=8, verbose=1, scoring='roc_auc' )\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "SVMGridSearch.fit(X_train,y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scale',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.01, average=False,\n",
       "                               class_weight='balanced', early_stopping=False,\n",
       "                               epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                               l1_ratio=0.15, learning_rate='optimal',\n",
       "                               loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
       "                               n_jobs=None, penalty='l2', power_t=0.5,\n",
       "                               random_state=101, shuffle=True, tol=0.001,\n",
       "                               validation_fraction=0.1, verbose=0,\n",
       "                               warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierEstimaterSVM =SVMGridSearch.best_estimator_\n",
    "classifierEstimaterSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-8562222c8e94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSVM_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvaluateClassifierEstimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifierEstimaterSVM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-496972435815>\u001b[0m in \u001b[0;36mEvaluateClassifierEstimator\u001b[1;34m(classifierEstimator, X, Y, cv)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#Perform cross validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     scores = cross_validate(classifierEstimator, X, Y, scoring=['accuracy','precision','recall']\n\u001b[0m\u001b[0;32m      5\u001b[0m                             , cv=cv, return_train_score=True)\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_validate' is not defined"
     ]
    }
   ],
   "source": [
    "SVM_scores = EvaluateClassifierEstimator(classifierEstimaterSVM,X_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "score_roc = SVMGridSearch.decision_function(X_test)\n",
    "fpr1, tpr1, thresholds = roc_curve(y_test, score_roc)\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "plt.figure(figsize=(8,5));\n",
    "plt.plot(fpr1, tpr1, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc1)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier accuracy with optimal parameters is: 71.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "\n",
    "clf_SVM = Pipeline(memory=None,\n",
    "                   steps=[('scale',StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
    "                          ('clf',\n",
    "                           SGDClassifier(alpha=0.01, average=False,\n",
    "                           class_weight='balanced', early_stopping=False,\n",
    "                           epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "                           l1_ratio=0.15, learning_rate='optimal',\n",
    "                           loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
    "                           n_jobs=None, penalty='l2', power_t=0.5,\n",
    "                           random_state=101, shuffle=True, tol=0.001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False))],verbose=False)\n",
    "\n",
    "clf_SVM.fit(X_train,y_train)\n",
    "yhatSVM = clf_SVM.predict(X_test)\n",
    "\n",
    "total_accuracy_SVM = mt.accuracy_score(y_test, yhatSVM)*100\n",
    "#Print out the results\n",
    "print('SVM classifier accuracy with optimal parameters is: %.1f'%(total_accuracy_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4968, 1150],\n",
       "       [2315, 3713]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, yhatSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2 KNN Classification Parameter Optimization with GridSearch\n",
    "\n",
    "K-Nearest Neighbor (KNN) classification is valid option for this dataset since the dataset has been preprocessed and it has no missing values.  Parameter selections are critical to the performance of KNN classifiers; therefore, substantial time and effort was put forth to fully investigate the optimal parameters. \n",
    "\n",
    "##### Parameter Analysis:\n",
    "\n",
    "*Algorithms:*  Algorithm used to compute the nearest neighbors can be ‘auto’matically determine the most appropriate algorithm to use for the given dataset/parameters, so it was left as default in our GridSearch\n",
    "\n",
    "##### GridSearch Parameters:\n",
    "\n",
    "*n_neighbors:* Number of neighbors to use in the analysis. Preliminary analyses were conducted to find a desired range of for number of neighbors. From these analyses, it was determined that the optimal number of neighbors is below 15. Above 15, the accuracy plateaus and start to decrease.\n",
    "\n",
    "*Leaf_size:* The leaf size was adjusted, using: 10, 30, and 100 as the parameters. While there is an over-head penalty with using smaller leaves, accuracy may increase, so we will use it in our Grid Search.\n",
    "\n",
    "*Metric:* How distance is measure between datapoints can be adjusted. The 2 options chosen were ‘minkowski’ and ‘euclidean’.\n",
    "\n",
    "*Weights:* Both uniform and distance were looked at. ‘Uniform’ weight-all neighboring points get equal weight. ‘Distance’ weights points by the inverse of their distance.\n",
    "\n",
    "*Predictor Variables:*  \n",
    "Many of the predictor variable have different scaling, so to ensure all variables were treated equally in the analysis, all predictor variables are scaled to have a mean of 0 and Standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7644726565338651\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "         'clf': [KNeighborsClassifier()],\n",
    "         'clf__weights': ['uniform','distance'],\n",
    "         'clf__leaf_size': [10,30],\n",
    "         'clf__metric': ['minkowski','euclidean'],\n",
    "         'clf__n_neighbors':[3,5,13,15,17],\n",
    "         \n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search_KNN = GridSearchCV(pipe, param_grid=param_grid,cv=k_fold,n_jobs=-1, verbose=1, scoring='roc_auc' )\n",
    "\n",
    "KNearest_model = grid_search_KNN.fit(X_train, y_train)\n",
    "\n",
    "y_KNN_score = grid_search_KNN.predict(X_test)\n",
    "\n",
    "y_KNN_prob=grid_search_KNN.predict_proba(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test, y_KNN_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scale',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=10,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=17, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierEstimaterKNN = KNearest_model.best_estimator_\n",
    "classifierEstimaterKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearch algorithm determined the following optimal parameters for K-Neighbors model.\n",
    "\n",
    "* Leaf-Size: 10  \n",
    "* Number of Neighbors: 13\n",
    "\n",
    "* Distance Matric: Minkowski  \n",
    "* Weights: Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNearest_scores = EvaluateClassifierEstimator(classifierEstimaterKNN,X_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test.loc[:,['cardio']].values.ravel(), y_KNN_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC Curve\n",
    "fpr2, tpr2, thresholds2 = roc_curve(y_test, y_KNN_prob[:,1] )\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "plt.figure(figsize=(8,5));\n",
    "plt.plot(fpr2, tpr2, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the KNN classification analysis with the optimal algorithm parameters that were determined by the parameter GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_knn = Pipeline(memory=None,\n",
    "         steps=[('scale',\n",
    "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
    "                ('clf',\n",
    "                 KNeighborsClassifier(algorithm='auto', leaf_size=10,\n",
    "                                      metric='minkowski', metric_params=None,\n",
    "                                      n_jobs=None, n_neighbors=13, p=2,\n",
    "                                      weights='uniform'))],\n",
    "         verbose=False)\n",
    "\n",
    "\n",
    "clf_knn.fit(X_train,y_train)\n",
    "yhatKNN = clf_knn.predict(X_test)\n",
    "\n",
    "total_accuracy_KNN = mt.accuracy_score(y_test, yhatKNN)*100\n",
    "#Print out the results\n",
    "print('KNN classifier accuracy with optimal parameters is: %.1f'%(total_accuracy_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3 Random Forest\n",
    "\n",
    "One of the most commonly used classifier techniques is random forest, due to its very low bias and general stability when it comes to classification. One method of optimizing a random forest model is to try different parameters to increase performance. Another method of doing so is by utilizing grid search to let random forest decide which combination of hyperparameters would be best implemented in your model. We chose this route as it saves both time and sanity when comparing so many different parameters.\n",
    "\n",
    "We'll start with a baseline random forest for our starting position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "         'clf': [RandomForestClassifier()],\n",
    "         'clf__n_estimators': [50, 100, 200, 500], \n",
    "         'clf__max_depth': [5,10,15,20,30],\n",
    "         'clf__random_state':[101]\n",
    "     }\n",
    "]\n",
    "\n",
    "grid_search_RF = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=1, scoring='roc_auc' )\n",
    "\n",
    "RandomForest_model = grid_search_RF.fit(X_train, y_train)\n",
    "\n",
    "y_RF_score = grid_search_RF.predict(X_test)\n",
    "y_RF_prob=grid_search_RF.predict_proba(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test, y_RF_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierEstimaterRF = RandomForest_model.best_estimator_\n",
    "classifierEstimaterRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_Forest_scores = EvaluateClassifierEstimator(classifierEstimaterRF,X_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_RF_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ROC cuve for Random Forest model:\n",
    "fpr3, tpr3, thresholds = roc_curve(y_test, y_RF_prob[:,1] )\n",
    "roc_auc3 = auc(fpr3, tpr3)\n",
    "\n",
    "plt.figure(figsize=(8,5));\n",
    "plt.plot(fpr3, tpr3, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc3)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF = Pipeline(memory=None,\n",
    "         steps=[('scale',\n",
    "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
    "                ('clf',\n",
    "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
    "                                        criterion='gini', max_depth=10,\n",
    "                                        max_features='auto',\n",
    "                                        max_leaf_nodes=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=1, min_samples_split=2,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=500, n_jobs=None,\n",
    "                                        oob_score=False, random_state=101,\n",
    "                                        verbose=0, warm_start=False))], verbose=False)\n",
    "\n",
    "clf_RF.fit(X_train,y_train)\n",
    "yhatRF = clf_RF.predict(X_test)\n",
    "\n",
    "total_accuracy_RF = mt.accuracy_score(y_test, yhatRF)*100\n",
    "#Print out the results\n",
    "print('Random Forest classifier accuracy with optimal parameters is: %.1f'%(total_accuracy_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #4 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "         'clf': [DecisionTreeClassifier()],\n",
    "         'clf__max_depth': [5,10,15,20,30],\n",
    "         'clf__random_state':[101] \n",
    "     }\n",
    "]\n",
    "\n",
    "\n",
    "# # This will test the parameter dict against our \n",
    "# # pipeline\n",
    "\n",
    "grid_searchDT = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=1, scoring='roc_auc')\n",
    "\n",
    "\n",
    "# # Here we are training the model, this is \n",
    "# # what takes the most amount of time to run\n",
    "DT_model = grid_searchDT.fit(X_train, y_train)\n",
    "\n",
    "y_DT_score = grid_searchDT.predict(X_test)\n",
    "y_DT_prob = grid_searchDT.predict_proba(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test, y_DT_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierEstimaterDT = DT_model.best_estimator_\n",
    "classifierEstimaterDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_scores = EvaluateClassifierEstimator(classifierEstimaterDT,X_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_DT_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ROC curve for Random Forest model:\n",
    "fpr4, tpr4, thresholds4 = roc_curve(y_test, y_DT_prob[:,1] )\n",
    "roc_auc4 = auc(fpr4, tpr4)\n",
    "\n",
    "plt.figure(figsize=(8,5));\n",
    "plt.plot(fpr4, tpr4, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc4)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_DT = Pipeline(memory=None,\n",
    "         steps=[('scale',\n",
    "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
    "                ('clf',\n",
    "                 DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
    "                                        max_depth=5, max_features=None,\n",
    "                                        max_leaf_nodes=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=1, min_samples_split=2,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        presort=False, random_state=101,\n",
    "                                        splitter='best'))],\n",
    "         verbose=False)\n",
    "\n",
    "clf_DT.fit(X_train,y_train)\n",
    "yhatDT = clf_DT.predict(X_test)\n",
    "\n",
    "total_accuracy_DT = mt.accuracy_score(y_test, yhatDT)*100\n",
    "#Print out the results\n",
    "print('Decision Tree Classifier accuracy with optimal parameters is: %.1f'%(total_accuracy_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### 1.2 Modeling and Evaluation 4<a id=\"1.2_Modeling_and_Evaluation_4\"></a>\n",
    "* Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model we found was Random Forest Classification, with a ROC/AUC score of ~.798. This is score lead to the conclusion that using this Random Forest Classification pipeline , could be used to accurately predict the expected valuation. Using this model to predict test set gives us 72.9% accuracy which is highest accuracy compared to other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9));\n",
    "plt.plot(fpr1, tpr1, color='darkorange', lw=1, label='SVM Calasifier (area = %0.3f)' % roc_auc1)\n",
    "plt.plot(fpr2, tpr2, color='red', lw=1, label='KNN Classifier (area = %0.3f)' % roc_auc2)\n",
    "plt.plot(fpr3, tpr3, color='black', lw=1, label='RF Calasifier (area = %0.3f)' % roc_auc3)\n",
    "#plt.plot(fpr4, tpr4, color='yellow', lw=1, label='DT Calasifier (area = %0.2f)' % roc_auc4)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9));\n",
    "plt.plot(fpr1, tpr1, color='darkorange', lw=1, label='SVM Calasifier (area = %0.3f)' % roc_auc1)\n",
    "plt.plot(fpr2, tpr2, color='red', lw=1, label='KNN Classifier (area = %0.3f)' % roc_auc2)\n",
    "plt.plot(fpr3, tpr3, color='black', lw=1, label='RF Calasifier (area = %0.3f)' % roc_auc3)\n",
    "plt.plot(fpr4, tpr4, color='yellow', lw=1, label='DT Calasifier (area = %0.3f)' % roc_auc4)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### 1.3 Modeling and Evaluation 5<a id=\"1.3_Modeling_and_Evaluation_5\"></a>\n",
    "* Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models we implemented: \n",
    "\n",
    "1.  **SVM**<br>\n",
    "        Advantage: \n",
    "            -Can handle large number of dimensions. \n",
    "            -Many kernels to choose from. \n",
    "            -Fairly robust against overfitting. \n",
    "        Disadvantage:\n",
    "            -Memory intensive and time consuming.\n",
    "            -Parameterization is hard.  \n",
    "\n",
    "2. **K-Nearest Neighbor**<br>\n",
    "        Advantage:\n",
    "            -Model does not need to be trained and incremental learning is done when new data is fed in. \n",
    "        Disadvantage:\n",
    "            -Does not handle large number of dimensions.\n",
    "            -Weighing of attributes needs to be done. Additional work.\n",
    "            -memory intensive. \n",
    "            \n",
    "3. **Random Forest** <br>\n",
    "        Advantage: \n",
    "            -Robust to overfitting. \n",
    "            -Performs well with large number of features.\n",
    "        Disadvantage: \n",
    "            -Learning is slow and integration to improve generated models is not possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Comparison of Classifiers: \n",
    "\n",
    "in case image doesn't show, equations restated: \n",
    "\n",
    "$$\\sigma^2 = \\frac{e(1-e)}{n}$$ \n",
    "\n",
    "$$CI = (e_1-e_2)\\pm1.96\\sqrt{(\\sigma_1^2+\\sigma_2^2)}$$\n",
    "\n",
    "\n",
    "## Comparison Models: \n",
    "### Compute variance for each model we are comparing\n",
    "\n",
    "##### SVM error and variance\n",
    "$\\sigma^2 = \\frac{e(1-e)}{n}$ <br><br>\n",
    "$e =.28$<br><br>\n",
    "$\\frac{(.28)(1-.28)}{12146} = {(1.66) 10^-5}$<br><br>\n",
    "\n",
    "##### K-Nearest Neighbor error and variance\n",
    "$\\sigma^2 = \\frac{e(1-e)}{n}$ <br><br>\n",
    "$e = .29$ <br><br>\n",
    "$\\frac{(.29)(1-.29)}{12146} =  {(1.7) 10^-5}$<br><br>\n",
    "    \n",
    "##### Random Forest error and variance\n",
    "$\\sigma^2 = \\frac{e(1-e)}{n}$ <br><br>\n",
    "$e =.27$<br><br>\n",
    "$\\frac{(.27)(1-.27)}{12146} = {(1.62) 10^-5}$<br><br>\n",
    "\n",
    " #### Bagging Model error and variance\n",
    "$\\sigma^2 = \\frac{e(1-e)}{n}$ <br><br>\n",
    "$e =.28$<br><br>\n",
    "$\\frac{(.28)(1-.28)}{12146} = {(1.66) 10^-5}$<br><br>\n",
    "\n",
    "### Compute Confidence intervals of various models\n",
    "\n",
    "##### SVM compared to K-Nearest Neighbor\n",
    "$(.28-.29)\\pm1.96\\sqrt{((1.66) 10^-5+(1.7) 10^-5} = [-0.0236, 0.0013]$<br>\n",
    "Our confidence interval does contain 0 so we are 95% confident that these two models are the same.<br>\n",
    "\n",
    "#####  SVM compared to Random Forest\n",
    "$(.28-.27)\\pm1.96\\sqrt{((1.66) 10^-5+(1.62) 10^-5)} = [0.0012, 0.021]$<br>\n",
    "Our confidence interval does not contain 0 so we are 95% confident that these two models are not the same.<br>\n",
    "\n",
    "#####  SVM compared to Decision Tree\n",
    "$(.28-.28)\\pm1.96\\sqrt{((1.66) 10^-5+(1.66) 10^-5)} = [-0.0112, 0.0112]$<br>\n",
    "Our confidence interval contains 0 so we are 95% confident that these two models are the same.<br>\n",
    "\n",
    "##### K-Nearest compared to Random Forest\n",
    "$(.29-.27)\\pm1.96\\sqrt{(1.62) 10^-5)+(1.7) 10^-5} = [0.0087, 0.0312]$<br>\n",
    "Our confidence interval does not contain 0 so we are 95% confident that these two models are not the same.<br>\n",
    "\n",
    "##### K-Nearest compared to Decision Tree\n",
    "$(.29-.28)\\pm1.96\\sqrt{((1.62) 10^-5)+(1.66) 10^-5)} = [-0.0236, 0.0013]$<br>\n",
    "Our confidence interval does contain 0 so we are 95% confident that these two models are the same.<br>\n",
    "\n",
    "##### Random Forest compared to Decision Tree\n",
    "$(.27-.28)\\pm1.96\\sqrt{((1.7) 10^-5+(1.66) 10^-5)} = [0.0012, 0.021]$<br>\n",
    "Our confidence interval does not contain 0 so we are 95% confident that these two models are not the same.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### 1.4 Modeling and Evaluation 6<a id=\"1.4_Modeling_and_Evaluation_6\"></a>\n",
    "* Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found out Random Forest classifier has the best performance on cardio in CVD dataset. Now, we proceed to find the Level of importance of each feature in this model.\n",
    "\n",
    "Whit this process we are trying to select those features that contribute most to the outcome we are trying to predict.   automatically. \n",
    "\n",
    "The benefits of feature selection include reduce overfitting, improving accuracy and minimizing computing time and putting irrelevant features in the model can decrease the accuracy of the models. \n",
    "\n",
    "* All features are scaled in the model.\n",
    "* The coefficient values indicate the level of feature influence on model performance, higher value means stronger influence and importance.\n",
    "* The influence values are sorted and top 20 features with strongest influences are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters of this estimator and fit the model\n",
    "pipe.set_params(**RandomForest_model.best_params_)\n",
    "pipe.fit(X, Y)\n",
    "\n",
    "coef = pipe.steps[1][1].feature_importances_\n",
    "\n",
    "feature_names=list(X_train.columns.values)\n",
    "\n",
    "#Creates a new dataframe with the coefficients and the features \n",
    "Top_Features = pd.DataFrame({'feature_names':feature_names, 'weights':coef})\n",
    "print(\"The Top Feature are the following\")\n",
    "display(Top_Features.sort_values(by='weights', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.barplot(x =Top_Features['weights'], y = Top_Features.sort_values(by='weights', ascending=False)['feature_names'], \n",
    "                 orient= 'h')\n",
    "ax.set_title(\"Top Feature Correlations\")\n",
    "ax.set_xlabel(\"Coefficient Magnitude\\n(z-score)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the coefficient shown above, it appears that ap_hi is the most important feature, followed by ap_lo, years, cholesterol, weight, height and others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the most influential features by Recursive Feature Elimination method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#Create an estimator with best parameters for cross validation\n",
    "classifierEst = RandomForestClassifier(bootstrap=True, class_weight=None,\n",
    "                                        criterion='gini', max_depth=10,\n",
    "                                        max_features='auto',\n",
    "                                        max_leaf_nodes=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=1, min_samples_split=2,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=500, n_jobs=None,\n",
    "                                        oob_score=False, random_state=101,\n",
    "                                        verbose=0, warm_start=False)\n",
    "\n",
    "rfecv = RFECV(estimator=classifierEst, step=1, cv=k_fold, scoring='accuracy')\n",
    "rfecv.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine categorical variables of interest  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find which features were eliminated\n",
    "eliminated_fea1 =[]\n",
    "for i in range(len(rfecv.ranking_)):\n",
    "    if rfecv.support_[i] == False:\n",
    "        eliminated_fea1.append(features[i])\n",
    "    \n",
    "    i+1\n",
    "    \n",
    "print(\"Eliminated features:\", eliminated_fea1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the RFE Rankings\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "rfe_ft_imp_df = pd.DataFrame({'feature_names':X.columns, 'weights':rfecv.grid_scores_})\n",
    "rfe_ft_imp_df.sort_values(by='weights', inplace=True, ascending=False )\n",
    "\n",
    "features = rfe_ft_imp_df\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use recursive feature elimination to get the best features for our model\n",
    "#(We already did this earlier)\n",
    "\n",
    "X_BestFeatures = rfecv.fit_transform(X, Y)\n",
    "\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "RandomForest_model.fit(X_BestFeatures, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateClassifierEstimator(RandomForest_model.best_estimator_, X_BestFeatures, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "# Task 2<a id=\"Task_1\"></a>\n",
    "\n",
    "### 2.1 Modeling and Evaluation 3<a id=\"2.1_Modeling_and_Evaluation_3\"></a>\n",
    "* Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are using 3 different classifiers to predict if patient cholesterol is in normal level or above level.As we mentioned previously there is imbalanced distribution in cholesterol classes and we can not use regular cross validation methods. We decided to combine 2 above normal classes together (as not normal cholesterol level '0') and use SMOTE technique to generate new samples for minor class in order to solve imbalanced situation. This technique is followed to avoid overfitting which occurs when exact replicas of minority instances are added to the main dataset. Addition to SMOTE there is another technique to deal with imbalanced distribution which called NearMiss. NearMiss is an under-sampling technique. Instead of resampling the Minority class, using a distance, this will make the majority class equal to minority class. For this task we used accuracy as a metric to evaluate 3 different models which are KNN , Random Forest and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining 2 above normal classes\n",
    "#change gender levels: 1 to 0 (female) and 2 to 1 (male)\n",
    "df['cholesterol'] = df['cholesterol'].apply(lambda x:0 if x == 2 or x == 3 else(1))\n",
    "#cholesterol percentage split\n",
    "(df['cholesterol'].value_counts()/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating input data into two parts X (features) and Y (target)\n",
    "features1 = [\"gender\", \"height\", \"weight\", \"ap_hi\", \"ap_lo\",\"cardio\", \"gluc\", \"smoke\", \"alco\", \"active\", \"years\", \"BMI\"]\n",
    "\n",
    "X1 = df[features1].copy()\n",
    "\n",
    "Y1= df[['cholesterol']].copy()\n",
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test split before resampling\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, Y1, test_size = 0.2, random_state = 101) \n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y1_train['cholesterol'] == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y1_train['cholesterol'] == 0))) \n",
    "  \n",
    "# import SMOTE module from imblearn library \n",
    "# pip install imblearn (if you don't have imblearn in your system) \n",
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state = 2) \n",
    "X1_train_res, y1_train_res = sm.fit_sample(X1_train, y1_train) \n",
    "  \n",
    "print('After OverSampling, the shape of train_X: {}'.format(X1_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y1_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y1_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y1_train_res == 0))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "         'clf': [KNeighborsClassifier()],\n",
    "         'clf__weights': ['uniform','distance'],\n",
    "         'clf__leaf_size': [10,30],\n",
    "         'clf__metric': ['minkowski','euclidean'],\n",
    "         'clf__n_neighbors':[3,5,13,15,17],\n",
    "         \n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search_KNN = GridSearchCV(pipe, param_grid=param_grid,cv=k_fold,n_jobs=-1, verbose=1, scoring='accuracy' )\n",
    "\n",
    "KNearest_model1 = grid_search_KNN.fit(X1_train_res, y1_train_res)\n",
    "\n",
    "y_KNN_score1 = grid_search_KNN.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierEstimaterKNN1 = KNearest_model1.best_estimator_\n",
    "classifierEstimaterKNN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNearest_scores1 = EvaluateClassifierEstimator(classifierEstimaterKNN1,X1_train_res,y1_train_res,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y1_test, y_KNN_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv=StratifiedKFold(n_splits=10,shuffle=True,random_state=101)\n",
    "KNN_accuracy = cross_val_score(classifierEstimaterKNN1, X1, y=Y1, cv=cv)\n",
    "KNN_acc=KNN_accuracy.mean()\n",
    "KNN_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "         'clf': [RandomForestClassifier()],\n",
    "         'clf__n_estimators': [50, 100, 200, 500], \n",
    "         'clf__max_depth': [5,10,15,20,30],\n",
    "         'clf__random_state':[101]\n",
    "     }\n",
    "]\n",
    "\n",
    "grid_search_RF = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=1, scoring='accuracy' )\n",
    "\n",
    "RandomForest_model1 = grid_search_RF.fit(X1_train_res, y1_train_res)\n",
    "\n",
    "y_RF_score1 = grid_search_RF.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierEstimaterRF1 = RandomForest_model1.best_estimator_\n",
    "classifierEstimaterRF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_Forest_scores1 = EvaluateClassifierEstimator(classifierEstimaterRF1,X1_train_res,y1_train_res,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y1_test, y_RF_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_accuracy = cross_val_score(classifierEstimaterRF1, X1, y=Y1, cv=cv)\n",
    "RF_acc=RF_accuracy.mean()\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = { 'clf':[LogisticRegression()]\n",
    "              ,'clf__penalty':['l2']\n",
    "              ,'clf__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'clf__class_weight': ['balanced','none']\n",
    "              ,'clf__random_state': [0]\n",
    "              ,'clf__solver': ['lbfgs']\n",
    "              ,'clf__max_iter':[1500,2000]\n",
    "              ,'clf__random_state':[101]\n",
    "             }\n",
    "\n",
    "grid_search_LR = GridSearchCV(pipe, param_grid=parameters, cv=k_fold,n_jobs=-1, verbose=1, scoring='accuracy' )\n",
    "\n",
    "LogisticRegression_model = grid_search_LR.fit(X1_train_res, y1_train_res)\n",
    "\n",
    "y_LR_score = grid_search_LR.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierEstimaterLR = LogisticRegression_model.best_estimator_\n",
    "classifierEstimaterLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_Regression_scores = EvaluateClassifierEstimator(classifierEstimaterLR,X1_train_res,y1_train_res,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y1_test, y_LR_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_accuracy = cross_val_score(classifierEstimaterLR, X1, y=Y1, cv=cv)\n",
    "LR_acc=LR_accuracy.mean()\n",
    "LR_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### 2.2 Modeling and Evaluation 4<a id=\"2.2_Modeling_and_Evaluation_4\"></a>\n",
    "* Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model we found was Random Forest Classification, with a accuracy score of ~.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('accuracy for KNN classifier is :',KNN_acc)\n",
    "print ('accuracy for Random Forest classifier is :',RF_acc)\n",
    "print ('accuracy for Logistic Regression classifier is :',LR_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### 2.3 Modeling and Evaluation 5<a id=\"2.3_Modeling_and_Evaluation_5\"></a>\n",
    "* Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Comparison of Classifiers: \n",
    "\n",
    "$$\\sigma^2 = \\frac{e(1-e)}{n}$$ \n",
    "\n",
    "$$CI = (e_1-e_2)\\pm1.96\\sqrt{(\\sigma_1^2+\\sigma_2^2)}$$\n",
    "\n",
    "\n",
    "## Comparison of Models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "n= len(Y1)\n",
    "KNN_error_var = KNN_acc*(1-KNN_acc)/n\n",
    "RF_error_var = RF_acc*(1-RF_acc)/n\n",
    "LR_error_var = LR_acc*(1-LR_acc)/n\n",
    "\n",
    "\n",
    "# calculating confidence interval\n",
    "KNN_RF_interval = 1.96 * sqrt(KNN_error_var + RF_error_var)\n",
    "KNN_LR_interval = 1.96 * sqrt(KNN_error_var + LR_error_var)\n",
    "RF_LR_interval = 1.96 * sqrt(RF_error_var + LR_error_var)\n",
    "\n",
    "\n",
    "print ('Range of KNN_RF confidence interval:[%0.6f,%0.6f]' %((KNN_acc - RF_acc)-KNN_RF_interval,\n",
    "                                  (KNN_acc - RF_acc)+KNN_RF_interval))\n",
    "print ('Range of KNN_LR confidence interval:[%0.6f,%0.6f]' %((KNN_acc - LR_acc)-KNN_LR_interval,\n",
    "                                  (KNN_acc - LR_acc)+KNN_LR_interval))\n",
    "print ('Range of RF_LR confidence interval:[%0.6f,%0.6f]' %((RF_acc - LR_acc)-RF_LR_interval,\n",
    "                                  (RF_acc - LR_acc)+RF_LR_interval))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of above confidence intervals contain 0 so we are 95% confident that all three models are not the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### 2.4 Modeling and Evaluation 6<a id=\"2.4_Modeling_and_Evaluation_6\"></a>\n",
    "* Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found out Random Forest classifier has the best performance on cholesterol in CVD dataset. Now, we proceed to find the Level of importance of each feature in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters of this estimator and fit the model\n",
    "pipe.set_params(**RandomForest_model1.best_params_)\n",
    "pipe.fit(X, Y)\n",
    "\n",
    "coef = pipe.steps[1][1].feature_importances_\n",
    "\n",
    "feature_names=list(X1_train.columns.values)\n",
    "\n",
    "#Creates a new dataframe with the coefficients and the features \n",
    "Top_Features = pd.DataFrame({'feature_names':feature_names, 'weights':coef})\n",
    "print(\"The Top Feature are the following\")\n",
    "display(Top_Features.sort_values(by='weights', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.barplot(x =Top_Features['weights'], y = Top_Features.sort_values(by='weights', ascending=False)['feature_names'], \n",
    "                 orient= 'h')\n",
    "ax.set_title(\"Top Feature Correlations\")\n",
    "ax.set_xlabel(\"Coefficient Magnitude\\n(z-score)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### Deployment<a id=\"Deployment\"></a>\n",
    "* How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would you deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "### Exceptional Work<a id=\"Exceptional_Work\"></a>\n",
    "* You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be looking at a Voting Classifier. Voting is one of the easyest ways of combining the predictions from multiple machine learning algorithms. Voting classifier isn’t an actual classifier but it wraps up different ones that are trained and valuated in parallel in order to look at the different uniqueness of each system. We will use and ensemble of different algorithms then predict the final output.\n",
    "\n",
    "This output on a prediction is taken by majority vote according to two different strategies:\n",
    "\n",
    "* Hard voting / Majority voting: Hard voting is the simplest case of majority voting. In this case, the class that received the highest number of votes will be chosen.\n",
    "Or\n",
    "* Soft Voting / Average probability: The probability vector for each predicted class are summed and the average is collected. The winning class is the one with the highest value.\n",
    "\n",
    "We will use both hard and soft voting ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "\n",
    "# Training classifiers\n",
    "\n",
    "clf1 = SGDClassifier(alpha=0.01, average=False,\n",
    "                           class_weight='balanced', early_stopping=False,\n",
    "                           epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "                           l1_ratio=0.15, learning_rate='optimal',\n",
    "                           loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
    "                           n_jobs=None, penalty='l2')\n",
    "\n",
    "clf2 = KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski', \n",
    "                                           metric_params=None, n_jobs=-1, n_neighbors=13, p=2,\n",
    "                                           weights='uniform')\n",
    "\n",
    "clf3 = RandomForestClassifier(bootstrap=True, class_weight=None,\n",
    "                                        criterion='gini', max_depth=10,\n",
    "                                        max_features='auto',\n",
    "                                        max_leaf_nodes=None,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=1, min_samples_split=2,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=500,random_state=101,\n",
    "                                        )\n",
    "\n",
    "clf4 = DecisionTreeClassifier(class_weight=None,criterion='gini',max_depth=5,splitter='best')\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('SVM', clf1), ('KNN', clf2),\n",
    "                                    ('RF', clf3),('DT',clf4)],voting='hard',)\n",
    "\n",
    "labels = ['SVM', 'KNN (k=13)', 'Random Forest (depth=10)','Decision Tree (depth=5)','Ensemble']\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3,clf4,eclf], labels):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X, Y, \n",
    "                                              cv=StratifiedKFold(n_splits=10, random_state=101), \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1_1 = SGDClassifier(alpha=0.01, average=False,\n",
    "                           class_weight='balanced', early_stopping=False,\n",
    "                           epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "                           l1_ratio=0.15, learning_rate='optimal',\n",
    "                           loss='modified_huber', max_iter=1000, n_iter_no_change=5,\n",
    "                           n_jobs=None, penalty='l2')\n",
    "\n",
    "eclf_soft = VotingClassifier(estimators=[('SVM', clf1_1), ('KNN', clf2),\n",
    "                                    ('RF', clf3),('DT',clf4)],voting='soft',)\n",
    "\n",
    "labels = ['SVM', 'KNN (k=13)', 'Random Forest (depth=10)','Decision Tree (depth=5)','Ensemble']\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3,clf4,eclf], labels):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X, Y, \n",
    "                                              cv=StratifiedKFold(n_splits=10, random_state=101), \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
